{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4e108fe-72a6-4053-bec2-af1a368594f2",
   "metadata": {},
   "source": [
    "## Environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d419c1d5-26ec-42d6-a6fb-e076dd903666",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os, time\n",
    "from datetime import datetime\n",
    "import importlib\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e9384f-3b1f-4210-b8cf-9cda27c00a8a",
   "metadata": {},
   "source": [
    "## Networks definitions and adaptations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ef53a8d-4d7c-4d1d-b914-8429d43fa8bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LUT NN definitions:\n",
      "layer1_lut_size 1024\n",
      "layer2_lut_size 256\n",
      "layer3_lut_size 32\n",
      "layer2_lutRangesCnt 16\n",
      "layer2_input_offset 8.0\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "from architecture_definitions import *\n",
    "\n",
    "oneOverPt = False \n",
    "lut_nn = True\n",
    "output_type = 0\n",
    "last_input_is_bias = True\n",
    "\n",
    "if output_type == 1:\n",
    "    layer3_neurons = 3\n",
    "    loss_fn = custom_loss3\n",
    "else: \n",
    "    output_cnt = 1\n",
    "    layer3_neurons = 1\n",
    "    loss_fn = 'mae'\n",
    "        \n",
    "if not last_input_is_bias:\n",
    "    networkInputSize =  nLayers\n",
    "    layer2_lutRangesCnt = 1\n",
    "    layer2_input_offset = None \n",
    " \n",
    "dir_postfix = get_lut_nn_dir_postfix() \n",
    "    \n",
    "print_LUT_NN()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630c86e0-bf1f-4a56-abf8-5762ea739a8f",
   "metadata": {},
   "source": [
    "### Training data set preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "165627dd-9c1c-41ea-b97a-ff97949c379a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from files:\n",
      "/scratch_ssd/akalinow/ProgrammingProjects/MachineLearning/OMTF/data/18_12_2020/OMTFHits_pats0x0003_oldSample_files_30_40_chunk_0.tfrecord.gzip\n",
      "/scratch_ssd/akalinow/ProgrammingProjects/MachineLearning/OMTF/data/18_12_2020/OMTFHits_pats0x0003_oldSample_files_15_25_chunk_0.tfrecord.gzip\n",
      "/scratch_ssd/akalinow/ProgrammingProjects/MachineLearning/OMTF/data/18_12_2020/OMTFHits_pats0x0003_oldSample_files_1_10_chunk_0.tfrecord.gzip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-16 16:54:12.589698: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-16 16:54:12.593838: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-16 16:54:12.594065: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-16 16:54:12.594468: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-16 16:54:12.595039: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-16 16:54:12.595213: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-16 16:54:12.595398: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-16 16:54:13.007041: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-16 16:54:13.007236: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-16 16:54:13.007392: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-16 16:54:13.007527: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 396 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 705 ms, sys: 143 ms, total: 847 ms\n",
      "Wall time: 896 ms\n"
     ]
    }
   ],
   "source": [
    "import io_functions as io\n",
    "importlib.reload(io)\n",
    "\n",
    "batchSize = 4096\n",
    "nEpochs = 1\n",
    "\n",
    "trainDataDir = \"/scratch_ssd/akalinow/ProgrammingProjects/MachineLearning/OMTF/data/18_12_2020/\"   \n",
    "trainFileNames = glob.glob(trainDataDir+'OMTFHits_pats0x0003_oldSample_files_*_chunk_0.tfrecord.gzip')\n",
    "\n",
    "dataset = io.get_LUT_NN_dataset(batchSize, nEpochs, trainFileNames, \n",
    "                                nRefLayers=nRefLayers,\n",
    "                                layer1_lut_size=layer1_lut_size,\n",
    "                                layer2_lut_size=layer2_lut_size,\n",
    "                                layer2_lutRangesCnt=layer2_lutRangesCnt,\n",
    "                                last_input_is_bias=last_input_is_bias,\n",
    "                                rangeFactor=rangeFactor,\n",
    "                                isTrain=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44abffd6-e9d9-47f0-9198-a84e8c7ac6b6",
   "metadata": {},
   "source": [
    "### Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d414507a-ce56-42f5-8edf-0a4064d77c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constructing LutInterLayer  layer1 lut_size 1024 num_inputs 19 num_outputs 16 input_offset 0\n",
      "write_lut_hist False hist_writer None\n",
      "constructing LutInterLayer  layer2 lut_size 256 num_inputs 16 num_outputs 8 input_offset 8.0\n",
      "write_lut_hist False hist_writer None\n",
      "constructing LutInterLayer  layer3 lut_size 32 num_inputs 8 num_outputs 1 input_offset None\n",
      "write_lut_hist False hist_writer None\n",
      "layer1 \n",
      "LutInterLayer.build: luts_float: layer1.luts_float:0 shape (18, 1024, 16)\n",
      "layer2 \n",
      "LutInterLayer.build: luts_float: layer2.luts_float:0 shape (16, 256, 8)\n",
      "layer3 \n",
      "LutInterLayer.build: luts_float: layer3.luts_float:0 shape (8, 32, 1)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " layer1 (LutInterLayer)      (None, 16)                313344    \n",
      "                                                                 \n",
      " layer2 (LutInterLayer)      (None, 8)                 36864     \n",
      "                                                                 \n",
      " layer3 (LutInterLayer)      (None, 1)                 512       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 350,720\n",
      "Trainable params: 327,936\n",
      "Non-trainable params: 22,784\n",
      "_________________________________________________________________\n",
      "CPU times: user 824 ms, sys: 30.5 ms, total: 854 ms\n",
      "Wall time: 860 ms\n"
     ]
    }
   ],
   "source": [
    "import model_functions as models\n",
    "importlib.reload(models)\n",
    "\n",
    "model = models.get_LUT_NN(last_input_is_bias=last_input_is_bias, loss_fn=loss_fn)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42a01e5-c7aa-4f68-87f1-c6a4e6270723",
   "metadata": {},
   "source": [
    "### The training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a48d01be-95ac-416b-8577-c23d3f8924b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training start. Current Time = 2023_Mar_16_16_54_40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-16 16:54:40.732454: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
      "2023-03-16 16:54:40.732479: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n",
      "2023-03-16 16:54:40.732507: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1665] Profiler found 1 GPUs\n",
      "2023-03-16 16:54:40.867211: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n",
      "2023-03-16 16:54:40.868678: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1799] CUPTI activity buffer flushed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "     14/Unknown - 1s 27ms/step - loss: 38.8906"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-16 16:54:42.271321: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
      "2023-03-16 16:54:42.271348: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     18/Unknown - 2s 29ms/step - loss: 38.5527"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-16 16:54:42.659796: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2023-03-16 16:54:42.670750: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1799] CUPTI activity buffer flushed\n",
      "2023-03-16 16:54:43.063636: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:521]  GpuTracer has collected 1638 callback api events and 1617 activity events. \n",
      "2023-03-16 16:54:43.395213: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n",
      "2023-03-16 16:54:44.229086: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: logs/fit/2023_Mar_16_16_54_40_lut_16_8_1/plugins/profile/2023_03_16_16_54_43\n",
      "\n",
      "2023-03-16 16:54:45.068738: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to logs/fit/2023_Mar_16_16_54_40_lut_16_8_1/plugins/profile/2023_03_16_16_54_43/73b2f5a183df.trace.json.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     27/Unknown - 5s 134ms/step - loss: 37.9417"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-16 16:54:45.427403: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: logs/fit/2023_Mar_16_16_54_40_lut_16_8_1/plugins/profile/2023_03_16_16_54_43\n",
      "\n",
      "2023-03-16 16:54:45.434622: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to logs/fit/2023_Mar_16_16_54_40_lut_16_8_1/plugins/profile/2023_03_16_16_54_43/73b2f5a183df.memory_profile.json.gz\n",
      "2023-03-16 16:54:45.442465: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: logs/fit/2023_Mar_16_16_54_40_lut_16_8_1/plugins/profile/2023_03_16_16_54_43\n",
      "Dumped tool data for xplane.pb to logs/fit/2023_Mar_16_16_54_40_lut_16_8_1/plugins/profile/2023_03_16_16_54_43/73b2f5a183df.xplane.pb\n",
      "Dumped tool data for overview_page.pb to logs/fit/2023_Mar_16_16_54_40_lut_16_8_1/plugins/profile/2023_03_16_16_54_43/73b2f5a183df.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to logs/fit/2023_Mar_16_16_54_40_lut_16_8_1/plugins/profile/2023_03_16_16_54_43/73b2f5a183df.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to logs/fit/2023_Mar_16_16_54_40_lut_16_8_1/plugins/profile/2023_03_16_16_54_43/73b2f5a183df.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to logs/fit/2023_Mar_16_16_54_40_lut_16_8_1/plugins/profile/2023_03_16_16_54_43/73b2f5a183df.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   5082/Unknown - 125s 24ms/step - loss: 15.5414\n",
      "Epoch 1: saving model to training/2023_Mar_16_16_54_40_lut_16_8_1/cp-0001.ckpt\n",
      "  10169/Unknown - 248s 24ms/step - loss: 14.0326\n",
      "Epoch 1: saving model to training/2023_Mar_16_16_54_40_lut_16_8_1/cp-0001.ckpt\n",
      "10171/10171 [==============================] - 248s 24ms/step - loss: 14.0323\n",
      "Epoch 2/10\n",
      " 5081/10171 [=============>................] - ETA: 2:04 - loss: 12.1516\n",
      "Epoch 2: saving model to training/2023_Mar_16_16_54_40_lut_16_8_1/cp-0002.ckpt\n",
      "10167/10171 [============================>.] - ETA: 0s - loss: 12.0761\n",
      "Epoch 2: saving model to training/2023_Mar_16_16_54_40_lut_16_8_1/cp-0002.ckpt\n",
      "10171/10171 [==============================] - 239s 24ms/step - loss: 12.0759\n",
      "Epoch 3/10\n",
      " 5082/10171 [=============>................] - ETA: 1:46 - loss: 11.9217\n",
      "Epoch 3: saving model to training/2023_Mar_16_16_54_40_lut_16_8_1/cp-0003.ckpt\n",
      "10165/10171 [============================>.] - ETA: 0s - loss: 11.8994\n",
      "Epoch 3: saving model to training/2023_Mar_16_16_54_40_lut_16_8_1/cp-0003.ckpt\n",
      "10171/10171 [==============================] - 211s 21ms/step - loss: 11.8991\n",
      "Epoch 4/10\n",
      " 5081/10171 [=============>................] - ETA: 1:45 - loss: 11.8538\n",
      "Epoch 4: saving model to training/2023_Mar_16_16_54_40_lut_16_8_1/cp-0004.ckpt\n",
      "10166/10171 [============================>.] - ETA: 0s - loss: 11.8462\n",
      "Epoch 4: saving model to training/2023_Mar_16_16_54_40_lut_16_8_1/cp-0004.ckpt\n",
      "10171/10171 [==============================] - 210s 21ms/step - loss: 11.8459\n",
      "Epoch 5/10\n",
      " 5080/10171 [=============>................] - ETA: 1:47 - loss: 11.8319\n",
      "Epoch 5: saving model to training/2023_Mar_16_16_54_40_lut_16_8_1/cp-0005.ckpt\n",
      "10163/10171 [============================>.] - ETA: 0s - loss: 11.8289\n",
      "Epoch 5: saving model to training/2023_Mar_16_16_54_40_lut_16_8_1/cp-0005.ckpt\n",
      "10171/10171 [==============================] - 213s 21ms/step - loss: 11.8286\n",
      "Epoch 6/10\n",
      " 5077/10171 [=============>................] - ETA: 1:44 - loss: 11.8247\n",
      "Epoch 6: saving model to training/2023_Mar_16_16_54_40_lut_16_8_1/cp-0006.ckpt\n",
      "10163/10171 [============================>.] - ETA: 0s - loss: 11.8235\n",
      "Epoch 6: saving model to training/2023_Mar_16_16_54_40_lut_16_8_1/cp-0006.ckpt\n",
      "10171/10171 [==============================] - 210s 21ms/step - loss: 11.8232\n",
      "Epoch 7/10\n",
      " 5077/10171 [=============>................] - ETA: 1:47 - loss: 11.8225\n",
      "Epoch 7: saving model to training/2023_Mar_16_16_54_40_lut_16_8_1/cp-0007.ckpt\n",
      "10163/10171 [============================>.] - ETA: 0s - loss: 11.8218\n",
      "Epoch 7: saving model to training/2023_Mar_16_16_54_40_lut_16_8_1/cp-0007.ckpt\n",
      "10171/10171 [==============================] - 214s 21ms/step - loss: 11.8215\n",
      "Epoch 8/10\n",
      " 5075/10171 [=============>................] - ETA: 1:45 - loss: 11.8216\n",
      "Epoch 8: saving model to training/2023_Mar_16_16_54_40_lut_16_8_1/cp-0008.ckpt\n",
      "10161/10171 [============================>.] - ETA: 0s - loss: 11.8213\n",
      "Epoch 8: saving model to training/2023_Mar_16_16_54_40_lut_16_8_1/cp-0008.ckpt\n",
      "10171/10171 [==============================] - 210s 21ms/step - loss: 11.8209\n",
      "Epoch 9/10\n",
      " 5074/10171 [=============>................] - ETA: 2:03 - loss: 11.8213\n",
      "Epoch 9: saving model to training/2023_Mar_16_16_54_40_lut_16_8_1/cp-0009.ckpt\n",
      "10160/10171 [============================>.] - ETA: 0s - loss: 11.8210\n",
      "Epoch 9: saving model to training/2023_Mar_16_16_54_40_lut_16_8_1/cp-0009.ckpt\n",
      "10171/10171 [==============================] - 247s 24ms/step - loss: 11.8208\n",
      "Epoch 10/10\n",
      " 5074/10171 [=============>................] - ETA: 1:46 - loss: 11.8213\n",
      "Epoch 10: saving model to training/2023_Mar_16_16_54_40_lut_16_8_1/cp-0010.ckpt\n",
      "10159/10171 [============================>.] - ETA: 0s - loss: 11.8209\n",
      "Epoch 10: saving model to training/2023_Mar_16_16_54_40_lut_16_8_1/cp-0010.ckpt\n",
      "10171/10171 [==============================] - 212s 21ms/step - loss: 11.8207\n",
      "INFO:tensorflow:Assets written to: training/2023_Mar_16_16_54_40_lut_16_8_1/assets\n",
      "Training end. Current Time = 2023_Mar_16_17_31_36\n",
      "CPU times: user 2h 16min 40s, sys: 33min 2s, total: 2h 49min 42s\n",
      "Wall time: 36min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "current_time = datetime.now().strftime(\"%Y_%b_%d_%H_%M_%S\")\n",
    "print(\"Training start. Current Time =\", current_time)\n",
    "\n",
    "nEpochs = 10\n",
    "\n",
    "log_dir = \"logs/fit/\" + current_time + dir_postfix\n",
    "job_dir = \"training/\" + current_time + dir_postfix\n",
    "\n",
    "checkpoint_path = job_dir + \"/cp-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1,\n",
    "                                                 save_freq = 5085)\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, profile_batch=(10, 20))\n",
    "\n",
    "model.save_weights(checkpoint_path.format(epoch=0))\n",
    "   \n",
    "model.fit(dataset, epochs=nEpochs, shuffle=True,\n",
    "            callbacks=[tensorboard_callback, cp_callback]\n",
    "            )\n",
    "model.save(job_dir, save_format='tf')\n",
    "\n",
    "current_time = datetime.now().strftime(\"%Y_%b_%d_%H_%M_%S\")\n",
    "print(\"Training end. Current Time =\", current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079be7a4-1270-4916-b798-bdaa00001094",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
